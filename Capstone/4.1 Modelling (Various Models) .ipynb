{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CAPSTONE PROJECT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "by Joyce Ooi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 3: Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains the code for model selection and evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "\n",
    "- [Importing of Libraries](#Importing-of-Libraries)\n",
    "- [Data Import](#Data-Import)\n",
    "- [Data Preparation](#Data-Preparation)\n",
    "- [Baseline Accuracy](#Baseline-Accuracy)\n",
    "- [Randomised Search for the Best Classifier](#Randomised-Search-for-the-Best-Classifier)\n",
    "- [Selection of the Best Classifier](#Selection-of-the-Best-Classifier)\n",
    "- [Further Exploration of the Best Classifier](#Further-Exploration-of-the-Best-Classifier)\n",
    "- [Generation of Predictions](#Generation-of-Predictions)\n",
    "- [Conclusion](#Conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing of Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Read in libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.ticker import (MultipleLocator, FormatStrFormatter,\n",
    "                               AutoMinorLocator)\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy.stats as stats\n",
    "from mpl_toolkits import mplot3d\n",
    "from sklearn import ensemble, preprocessing\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics import silhouette_score\n",
    "#modelling\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc, roc_auc_score, accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, GRU\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "\n",
    "# import xgboost as xgb\n",
    "# from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data from downloaded csv files\n",
    "train=pd.read_csv('./datasets/tsla_train.csv')\n",
    "test_actual=pd.read_csv('./datasets/tsla_test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1970, 50), (466, 50))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test_actual.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>tsla_intra_target</th>\n",
       "      <th>tsla_sentiment</th>\n",
       "      <th>em_tweets3_sentiment</th>\n",
       "      <th>dax_return</th>\n",
       "      <th>cac_return</th>\n",
       "      <th>dji_previous_day_return</th>\n",
       "      <th>MA5</th>\n",
       "      <th>MA10</th>\n",
       "      <th>...</th>\n",
       "      <th>em_tweets3_sentiment_lag3</th>\n",
       "      <th>dax_return_lag3</th>\n",
       "      <th>cac_return_lag3</th>\n",
       "      <th>dji_previous_day_return_lag3</th>\n",
       "      <th>MA5_lag3</th>\n",
       "      <th>MA10_lag3</th>\n",
       "      <th>MA20_lag3</th>\n",
       "      <th>MA50_lag3</th>\n",
       "      <th>change_lag3</th>\n",
       "      <th>volatity_lag3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>2010-08-12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>18.490</td>\n",
       "      <td>19.168</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>19.986</td>\n",
       "      <td>19.824</td>\n",
       "      <td>19.7955</td>\n",
       "      <td>19.6968</td>\n",
       "      <td>0.000510</td>\n",
       "      <td>0.041525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31</td>\n",
       "      <td>2010-08-13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>18.326</td>\n",
       "      <td>18.919</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.314</td>\n",
       "      <td>19.662</td>\n",
       "      <td>19.6860</td>\n",
       "      <td>19.6720</td>\n",
       "      <td>-0.029513</td>\n",
       "      <td>0.041491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>2010-08-16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>18.350</td>\n",
       "      <td>18.753</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>18.744</td>\n",
       "      <td>19.448</td>\n",
       "      <td>19.6450</td>\n",
       "      <td>19.7104</td>\n",
       "      <td>-0.061216</td>\n",
       "      <td>0.041826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>2010-08-17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>18.524</td>\n",
       "      <td>18.704</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>18.490</td>\n",
       "      <td>19.168</td>\n",
       "      <td>19.5775</td>\n",
       "      <td>19.8278</td>\n",
       "      <td>-0.016902</td>\n",
       "      <td>0.042109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34</td>\n",
       "      <td>2010-08-18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.762</td>\n",
       "      <td>18.757</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>18.326</td>\n",
       "      <td>18.919</td>\n",
       "      <td>19.5365</td>\n",
       "      <td>19.9306</td>\n",
       "      <td>0.040094</td>\n",
       "      <td>0.036775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>125</td>\n",
       "      <td>2010-12-28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>28.482</td>\n",
       "      <td>29.086</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31.608</td>\n",
       "      <td>29.894</td>\n",
       "      <td>29.5570</td>\n",
       "      <td>29.3088</td>\n",
       "      <td>0.011404</td>\n",
       "      <td>0.037154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>126</td>\n",
       "      <td>2010-12-29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.256</td>\n",
       "      <td>28.612</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.446</td>\n",
       "      <td>29.814</td>\n",
       "      <td>29.3205</td>\n",
       "      <td>29.1912</td>\n",
       "      <td>-0.081039</td>\n",
       "      <td>0.033302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>127</td>\n",
       "      <td>2010-12-30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.564</td>\n",
       "      <td>28.109</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.388</td>\n",
       "      <td>29.504</td>\n",
       "      <td>29.0960</td>\n",
       "      <td>29.0780</td>\n",
       "      <td>-0.163556</td>\n",
       "      <td>0.036518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>128</td>\n",
       "      <td>2010-12-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>26.778</td>\n",
       "      <td>27.566</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>28.482</td>\n",
       "      <td>29.086</td>\n",
       "      <td>28.9055</td>\n",
       "      <td>28.9702</td>\n",
       "      <td>0.033105</td>\n",
       "      <td>0.049272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>129</td>\n",
       "      <td>2011-01-03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.830</td>\n",
       "      <td>27.091</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.256</td>\n",
       "      <td>28.612</td>\n",
       "      <td>28.7520</td>\n",
       "      <td>28.8506</td>\n",
       "      <td>0.048772</td>\n",
       "      <td>0.050365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0        date  tsla_intra_target  tsla_sentiment  \\\n",
       "0           30  2010-08-12                1.0             0.0   \n",
       "1           31  2010-08-13                0.0             0.0   \n",
       "2           32  2010-08-16                0.0             0.0   \n",
       "3           33  2010-08-17                0.0             0.0   \n",
       "4           34  2010-08-18                1.0             0.0   \n",
       "..         ...         ...                ...             ...   \n",
       "95         125  2010-12-28                0.0             0.0   \n",
       "96         126  2010-12-29                0.0             0.0   \n",
       "97         127  2010-12-30                1.0             0.0   \n",
       "98         128  2010-12-31                0.0             0.0   \n",
       "99         129  2011-01-03                1.0             0.0   \n",
       "\n",
       "    em_tweets3_sentiment  dax_return  cac_return  dji_previous_day_return  \\\n",
       "0                    0.0        -1.0         1.0                     -1.0   \n",
       "1                    0.0        -1.0        -1.0                     -1.0   \n",
       "2                    0.0        -1.0        -1.0                     -1.0   \n",
       "3                    0.0         1.0         1.0                     -1.0   \n",
       "4                    0.0         1.0        -1.0                      1.0   \n",
       "..                   ...         ...         ...                      ...   \n",
       "95                   0.0        -1.0        -1.0                     -1.0   \n",
       "96                   0.0         1.0         1.0                      1.0   \n",
       "97                   0.0        -1.0        -1.0                      1.0   \n",
       "98                   0.0         0.0         0.0                     -1.0   \n",
       "99                   0.0         1.0         1.0                      1.0   \n",
       "\n",
       "       MA5    MA10  ...  em_tweets3_sentiment_lag3  dax_return_lag3  \\\n",
       "0   18.490  19.168  ...                        0.0              1.0   \n",
       "1   18.326  18.919  ...                        0.0             -1.0   \n",
       "2   18.350  18.753  ...                        0.0             -1.0   \n",
       "3   18.524  18.704  ...                        0.0             -1.0   \n",
       "4   18.762  18.757  ...                        0.0             -1.0   \n",
       "..     ...     ...  ...                        ...              ...   \n",
       "95  28.482  29.086  ...                        0.0             -1.0   \n",
       "96  27.256  28.612  ...                        0.0             -1.0   \n",
       "97  26.564  28.109  ...                        0.0             -1.0   \n",
       "98  26.778  27.566  ...                        0.0             -1.0   \n",
       "99  26.830  27.091  ...                        0.0              1.0   \n",
       "\n",
       "    cac_return_lag3  dji_previous_day_return_lag3  MA5_lag3  MA10_lag3  \\\n",
       "0               1.0                          -1.0    19.986     19.824   \n",
       "1              -1.0                           1.0    19.314     19.662   \n",
       "2              -1.0                          -1.0    18.744     19.448   \n",
       "3               1.0                          -1.0    18.490     19.168   \n",
       "4              -1.0                          -1.0    18.326     18.919   \n",
       "..              ...                           ...       ...        ...   \n",
       "95             -1.0                           1.0    31.608     29.894   \n",
       "96             -1.0                           1.0    30.446     29.814   \n",
       "97             -1.0                           1.0    29.388     29.504   \n",
       "98             -1.0                          -1.0    28.482     29.086   \n",
       "99              1.0                           1.0    27.256     28.612   \n",
       "\n",
       "    MA20_lag3  MA50_lag3  change_lag3  volatity_lag3  \n",
       "0     19.7955    19.6968     0.000510       0.041525  \n",
       "1     19.6860    19.6720    -0.029513       0.041491  \n",
       "2     19.6450    19.7104    -0.061216       0.041826  \n",
       "3     19.5775    19.8278    -0.016902       0.042109  \n",
       "4     19.5365    19.9306     0.040094       0.036775  \n",
       "..        ...        ...          ...            ...  \n",
       "95    29.5570    29.3088     0.011404       0.037154  \n",
       "96    29.3205    29.1912    -0.081039       0.033302  \n",
       "97    29.0960    29.0780    -0.163556       0.036518  \n",
       "98    28.9055    28.9702     0.033105       0.049272  \n",
       "99    28.7520    28.8506     0.048772       0.050365  \n",
       "\n",
       "[100 rows x 50 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>tsla_intra_target</th>\n",
       "      <th>tsla_sentiment</th>\n",
       "      <th>em_tweets3_sentiment</th>\n",
       "      <th>dax_return</th>\n",
       "      <th>cac_return</th>\n",
       "      <th>dji_previous_day_return</th>\n",
       "      <th>MA5</th>\n",
       "      <th>MA10</th>\n",
       "      <th>...</th>\n",
       "      <th>em_tweets3_sentiment_lag3</th>\n",
       "      <th>dax_return_lag3</th>\n",
       "      <th>cac_return_lag3</th>\n",
       "      <th>dji_previous_day_return_lag3</th>\n",
       "      <th>MA5_lag3</th>\n",
       "      <th>MA10_lag3</th>\n",
       "      <th>MA20_lag3</th>\n",
       "      <th>MA50_lag3</th>\n",
       "      <th>change_lag3</th>\n",
       "      <th>volatity_lag3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000</td>\n",
       "      <td>2018-06-11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>325.623999</td>\n",
       "      <td>321.031000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>303.056000</td>\n",
       "      <td>302.525003</td>\n",
       "      <td>309.739502</td>\n",
       "      <td>312.464601</td>\n",
       "      <td>0.092987</td>\n",
       "      <td>0.021095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001</td>\n",
       "      <td>2018-06-12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>330.679999</td>\n",
       "      <td>327.666000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>308.223999</td>\n",
       "      <td>308.426001</td>\n",
       "      <td>313.142502</td>\n",
       "      <td>312.965801</td>\n",
       "      <td>-0.010730</td>\n",
       "      <td>0.028782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2002</td>\n",
       "      <td>2018-06-13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>339.006000</td>\n",
       "      <td>335.075000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>315.296002</td>\n",
       "      <td>313.732001</td>\n",
       "      <td>317.503001</td>\n",
       "      <td>313.301601</td>\n",
       "      <td>0.004955</td>\n",
       "      <td>0.028909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003</td>\n",
       "      <td>2018-06-14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>347.108002</td>\n",
       "      <td>341.216998</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>325.623999</td>\n",
       "      <td>321.031000</td>\n",
       "      <td>320.925001</td>\n",
       "      <td>313.656001</td>\n",
       "      <td>0.044455</td>\n",
       "      <td>0.028744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2004</td>\n",
       "      <td>2018-06-15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>354.853998</td>\n",
       "      <td>345.488998</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>330.679999</td>\n",
       "      <td>327.666000</td>\n",
       "      <td>323.714001</td>\n",
       "      <td>314.169001</td>\n",
       "      <td>0.031623</td>\n",
       "      <td>0.030147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        date  tsla_intra_target  tsla_sentiment  \\\n",
       "0        2000  2018-06-11                0.0             1.0   \n",
       "1        2001  2018-06-12                1.0            -1.0   \n",
       "2        2002  2018-06-13                1.0             1.0   \n",
       "3        2003  2018-06-14                0.0            -1.0   \n",
       "4        2004  2018-06-15                0.0             0.0   \n",
       "\n",
       "   em_tweets3_sentiment  dax_return  cac_return  dji_previous_day_return  \\\n",
       "0                  -1.0         1.0         1.0                      1.0   \n",
       "1                  -1.0        -1.0        -1.0                     -1.0   \n",
       "2                   1.0         1.0        -1.0                     -1.0   \n",
       "3                  -1.0         1.0         1.0                     -1.0   \n",
       "4                   1.0        -1.0        -1.0                     -1.0   \n",
       "\n",
       "          MA5        MA10  ...  em_tweets3_sentiment_lag3  dax_return_lag3  \\\n",
       "0  325.623999  321.031000  ...                       -1.0              1.0   \n",
       "1  330.679999  327.666000  ...                        1.0             -1.0   \n",
       "2  339.006000  335.075000  ...                        1.0              1.0   \n",
       "3  347.108002  341.216998  ...                       -1.0              1.0   \n",
       "4  354.853998  345.488998  ...                       -1.0             -1.0   \n",
       "\n",
       "   cac_return_lag3  dji_previous_day_return_lag3    MA5_lag3   MA10_lag3  \\\n",
       "0             -1.0                          -1.0  303.056000  302.525003   \n",
       "1             -1.0                           1.0  308.223999  308.426001   \n",
       "2              1.0                           1.0  315.296002  313.732001   \n",
       "3              1.0                           1.0  325.623999  321.031000   \n",
       "4             -1.0                          -1.0  330.679999  327.666000   \n",
       "\n",
       "    MA20_lag3   MA50_lag3  change_lag3  volatity_lag3  \n",
       "0  309.739502  312.464601     0.092987       0.021095  \n",
       "1  313.142502  312.965801    -0.010730       0.028782  \n",
       "2  317.503001  313.301601     0.004955       0.028909  \n",
       "3  320.925001  313.656001     0.044455       0.028744  \n",
       "4  323.714001  314.169001     0.031623       0.030147  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_actual.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(['Unnamed: 0'], axis = 1)\n",
    "test_actual = test_actual.drop(['Unnamed: 0'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tsla_intra_target</th>\n",
       "      <th>tsla_sentiment</th>\n",
       "      <th>em_tweets3_sentiment</th>\n",
       "      <th>dax_return</th>\n",
       "      <th>cac_return</th>\n",
       "      <th>dji_previous_day_return</th>\n",
       "      <th>MA5</th>\n",
       "      <th>MA10</th>\n",
       "      <th>MA20</th>\n",
       "      <th>...</th>\n",
       "      <th>em_tweets3_sentiment_lag3</th>\n",
       "      <th>dax_return_lag3</th>\n",
       "      <th>cac_return_lag3</th>\n",
       "      <th>dji_previous_day_return_lag3</th>\n",
       "      <th>MA5_lag3</th>\n",
       "      <th>MA10_lag3</th>\n",
       "      <th>MA20_lag3</th>\n",
       "      <th>MA50_lag3</th>\n",
       "      <th>change_lag3</th>\n",
       "      <th>volatity_lag3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-08-12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>18.490</td>\n",
       "      <td>19.168</td>\n",
       "      <td>19.5775</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>19.986</td>\n",
       "      <td>19.824</td>\n",
       "      <td>19.7955</td>\n",
       "      <td>19.6968</td>\n",
       "      <td>0.000510</td>\n",
       "      <td>0.041525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-08-13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>18.326</td>\n",
       "      <td>18.919</td>\n",
       "      <td>19.5365</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.314</td>\n",
       "      <td>19.662</td>\n",
       "      <td>19.6860</td>\n",
       "      <td>19.6720</td>\n",
       "      <td>-0.029513</td>\n",
       "      <td>0.041491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-08-16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>18.350</td>\n",
       "      <td>18.753</td>\n",
       "      <td>19.5065</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>18.744</td>\n",
       "      <td>19.448</td>\n",
       "      <td>19.6450</td>\n",
       "      <td>19.7104</td>\n",
       "      <td>-0.061216</td>\n",
       "      <td>0.041826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-08-17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>18.524</td>\n",
       "      <td>18.704</td>\n",
       "      <td>19.4945</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>18.490</td>\n",
       "      <td>19.168</td>\n",
       "      <td>19.5775</td>\n",
       "      <td>19.8278</td>\n",
       "      <td>-0.016902</td>\n",
       "      <td>0.042109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-08-18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.762</td>\n",
       "      <td>18.757</td>\n",
       "      <td>19.4420</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>18.326</td>\n",
       "      <td>18.919</td>\n",
       "      <td>19.5365</td>\n",
       "      <td>19.9306</td>\n",
       "      <td>0.040094</td>\n",
       "      <td>0.036775</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  tsla_intra_target  tsla_sentiment  em_tweets3_sentiment  \\\n",
       "0  2010-08-12                1.0             0.0                   0.0   \n",
       "1  2010-08-13                0.0             0.0                   0.0   \n",
       "2  2010-08-16                0.0             0.0                   0.0   \n",
       "3  2010-08-17                0.0             0.0                   0.0   \n",
       "4  2010-08-18                1.0             0.0                   0.0   \n",
       "\n",
       "   dax_return  cac_return  dji_previous_day_return     MA5    MA10     MA20  \\\n",
       "0        -1.0         1.0                     -1.0  18.490  19.168  19.5775   \n",
       "1        -1.0        -1.0                     -1.0  18.326  18.919  19.5365   \n",
       "2        -1.0        -1.0                     -1.0  18.350  18.753  19.5065   \n",
       "3         1.0         1.0                     -1.0  18.524  18.704  19.4945   \n",
       "4         1.0        -1.0                      1.0  18.762  18.757  19.4420   \n",
       "\n",
       "   ...  em_tweets3_sentiment_lag3  dax_return_lag3  cac_return_lag3  \\\n",
       "0  ...                        0.0              1.0              1.0   \n",
       "1  ...                        0.0             -1.0             -1.0   \n",
       "2  ...                        0.0             -1.0             -1.0   \n",
       "3  ...                        0.0             -1.0              1.0   \n",
       "4  ...                        0.0             -1.0             -1.0   \n",
       "\n",
       "   dji_previous_day_return_lag3  MA5_lag3  MA10_lag3  MA20_lag3  MA50_lag3  \\\n",
       "0                          -1.0    19.986     19.824    19.7955    19.6968   \n",
       "1                           1.0    19.314     19.662    19.6860    19.6720   \n",
       "2                          -1.0    18.744     19.448    19.6450    19.7104   \n",
       "3                          -1.0    18.490     19.168    19.5775    19.8278   \n",
       "4                          -1.0    18.326     18.919    19.5365    19.9306   \n",
       "\n",
       "   change_lag3  volatity_lag3  \n",
       "0     0.000510       0.041525  \n",
       "1    -0.029513       0.041491  \n",
       "2    -0.061216       0.041826  \n",
       "3    -0.016902       0.042109  \n",
       "4     0.040094       0.036775  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tsla_intra_target</th>\n",
       "      <th>tsla_sentiment</th>\n",
       "      <th>em_tweets3_sentiment</th>\n",
       "      <th>dax_return</th>\n",
       "      <th>cac_return</th>\n",
       "      <th>dji_previous_day_return</th>\n",
       "      <th>MA5</th>\n",
       "      <th>MA10</th>\n",
       "      <th>MA20</th>\n",
       "      <th>...</th>\n",
       "      <th>em_tweets3_sentiment_lag3</th>\n",
       "      <th>dax_return_lag3</th>\n",
       "      <th>cac_return_lag3</th>\n",
       "      <th>dji_previous_day_return_lag3</th>\n",
       "      <th>MA5_lag3</th>\n",
       "      <th>MA10_lag3</th>\n",
       "      <th>MA20_lag3</th>\n",
       "      <th>MA50_lag3</th>\n",
       "      <th>change_lag3</th>\n",
       "      <th>volatity_lag3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-06-11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>325.623999</td>\n",
       "      <td>321.031000</td>\n",
       "      <td>320.925001</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>303.056000</td>\n",
       "      <td>302.525003</td>\n",
       "      <td>309.739502</td>\n",
       "      <td>312.464601</td>\n",
       "      <td>0.092987</td>\n",
       "      <td>0.021095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-06-12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>330.679999</td>\n",
       "      <td>327.666000</td>\n",
       "      <td>323.714001</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>308.223999</td>\n",
       "      <td>308.426001</td>\n",
       "      <td>313.142502</td>\n",
       "      <td>312.965801</td>\n",
       "      <td>-0.010730</td>\n",
       "      <td>0.028782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-06-13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>339.006000</td>\n",
       "      <td>335.075000</td>\n",
       "      <td>326.422002</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>315.296002</td>\n",
       "      <td>313.732001</td>\n",
       "      <td>317.503001</td>\n",
       "      <td>313.301601</td>\n",
       "      <td>0.004955</td>\n",
       "      <td>0.028909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-06-14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>347.108002</td>\n",
       "      <td>341.216998</td>\n",
       "      <td>329.334001</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>325.623999</td>\n",
       "      <td>321.031000</td>\n",
       "      <td>320.925001</td>\n",
       "      <td>313.656001</td>\n",
       "      <td>0.044455</td>\n",
       "      <td>0.028744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-06-15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>354.853998</td>\n",
       "      <td>345.488998</td>\n",
       "      <td>331.973001</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>330.679999</td>\n",
       "      <td>327.666000</td>\n",
       "      <td>323.714001</td>\n",
       "      <td>314.169001</td>\n",
       "      <td>0.031623</td>\n",
       "      <td>0.030147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  tsla_intra_target  tsla_sentiment  em_tweets3_sentiment  \\\n",
       "0  2018-06-11                0.0             1.0                  -1.0   \n",
       "1  2018-06-12                1.0            -1.0                  -1.0   \n",
       "2  2018-06-13                1.0             1.0                   1.0   \n",
       "3  2018-06-14                0.0            -1.0                  -1.0   \n",
       "4  2018-06-15                0.0             0.0                   1.0   \n",
       "\n",
       "   dax_return  cac_return  dji_previous_day_return         MA5        MA10  \\\n",
       "0         1.0         1.0                      1.0  325.623999  321.031000   \n",
       "1        -1.0        -1.0                     -1.0  330.679999  327.666000   \n",
       "2         1.0        -1.0                     -1.0  339.006000  335.075000   \n",
       "3         1.0         1.0                     -1.0  347.108002  341.216998   \n",
       "4        -1.0        -1.0                     -1.0  354.853998  345.488998   \n",
       "\n",
       "         MA20  ...  em_tweets3_sentiment_lag3  dax_return_lag3  \\\n",
       "0  320.925001  ...                       -1.0              1.0   \n",
       "1  323.714001  ...                        1.0             -1.0   \n",
       "2  326.422002  ...                        1.0              1.0   \n",
       "3  329.334001  ...                       -1.0              1.0   \n",
       "4  331.973001  ...                       -1.0             -1.0   \n",
       "\n",
       "   cac_return_lag3  dji_previous_day_return_lag3    MA5_lag3   MA10_lag3  \\\n",
       "0             -1.0                          -1.0  303.056000  302.525003   \n",
       "1             -1.0                           1.0  308.223999  308.426001   \n",
       "2              1.0                           1.0  315.296002  313.732001   \n",
       "3              1.0                           1.0  325.623999  321.031000   \n",
       "4             -1.0                          -1.0  330.679999  327.666000   \n",
       "\n",
       "    MA20_lag3   MA50_lag3  change_lag3  volatity_lag3  \n",
       "0  309.739502  312.464601     0.092987       0.021095  \n",
       "1  313.142502  312.965801    -0.010730       0.028782  \n",
       "2  317.503001  313.301601     0.004955       0.028909  \n",
       "3  320.925001  313.656001     0.044455       0.028744  \n",
       "4  323.714001  314.169001     0.031623       0.030147  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_actual.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date                            0\n",
       "tsla_intra_target               0\n",
       "tsla_sentiment                  0\n",
       "em_tweets3_sentiment            0\n",
       "dax_return                      0\n",
       "cac_return                      0\n",
       "dji_previous_day_return         0\n",
       "MA5                             0\n",
       "MA10                            0\n",
       "MA20                            0\n",
       "MA50                            0\n",
       "change                          0\n",
       "volatility                      0\n",
       "tsla_intra_target_lag1          0\n",
       "tsla_sentiment_lag1             0\n",
       "em_tweets3_sentiment_lag1       0\n",
       "dax_return_lag1                 0\n",
       "cac_return_lag1                 0\n",
       "dji_previous_day_return_lag1    0\n",
       "MA5_lag1                        0\n",
       "MA10_lag1                       0\n",
       "MA20_lag1                       0\n",
       "MA50_lag1                       0\n",
       "change_lag1                     0\n",
       "volatity_lag1                   0\n",
       "tsla_intra_target_lag2          0\n",
       "tsla_sentiment_lag2             0\n",
       "em_tweets3_sentiment_lag2       0\n",
       "dax_return_lag2                 0\n",
       "cac_return_lag2                 0\n",
       "dji_previous_day_return_lag2    0\n",
       "MA5_lag2                        0\n",
       "MA10_lag2                       0\n",
       "MA20_lag2                       0\n",
       "MA50_lag2                       0\n",
       "change_lag2                     0\n",
       "volatity_lag2                   0\n",
       "tsla_intra_target_lag3          0\n",
       "tsla_sentiment_lag3             0\n",
       "em_tweets3_sentiment_lag3       0\n",
       "dax_return_lag3                 0\n",
       "cac_return_lag3                 0\n",
       "dji_previous_day_return_lag3    0\n",
       "MA5_lag3                        0\n",
       "MA10_lag3                       0\n",
       "MA20_lag3                       0\n",
       "MA50_lag3                       0\n",
       "change_lag3                     0\n",
       "volatity_lag3                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['date']=pd.to_datetime(train['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_actual['date']=pd.to_datetime(test_actual['date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train.shape, test_actual.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X and Y variable\n",
    "X = train.drop(columns = ['tsla_intra_target', 'date']) \n",
    "y = train['tsla_intra_target']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_testuntrain = test_actual.drop(columns = ['tsla_intra_target','date']) \n",
    "y_testuntrain = test_actual['tsla_intra_target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train Test split \n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.25,\n",
    "                                                    random_state=42,\n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_test = test.drop(['    '], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    0.508463\n",
       "0.0    0.491537\n",
       "Name: tsla_intra_target, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe above that the baseline accuracy (for predicting an intraday positive return for Tesla stock) is approximately 51.18%. The naive model will predict all 1s and will be correct 51.18% of the time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balanced Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The baseline accuracy above indicates that the **training set is balanced** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Randomised Search for the Best Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To manage the total time and resources used to tune the hyperparameters, we use the RandomizedSearchCV to randomly find the optimal parameters for each of the models based on the training dataset, with a maximum of 50 iterations. We specify the range of parameters to be used by RandomizedSearchCV for each classifer, based on experience and past results of running the RandomizedSearchCV.\n",
    "\n",
    "We obtain the various scores on the validation dataset for each classifier using the optimal parameters identified by RandomizedSearchCV. We will select the best classifier based on the **highest F1 and Accuracy score** found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We fit a StandardScaler() object on just the training dataset,\n",
    "# then use the object to transform both the training and validation datasets\n",
    "\n",
    "ss = StandardScaler()\n",
    "X_train_sc = ss.fit_transform(X_train) #fit with X train data and use it to transform both X_train and X_valid data\n",
    "X_valid_sc = ss.transform(X_valid)\n",
    "\n",
    "X_testuntrain_sc = ss.transform(X_testuntrain) #use the same fit above with X train data on the untrained (test_actual) data set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have selected the models below for modelling purposes.\n",
    "estimators = {\n",
    "    'lr': LogisticRegression(random_state=42),\n",
    "    'knn': KNeighborsClassifier(),\n",
    "    'ada': AdaBoostClassifier(random_state=42),\n",
    "    'dtree': DecisionTreeClassifier(random_state=42),\n",
    "    'rf': RandomForestClassifier(random_state=42),\n",
    "    'etree': ExtraTreesClassifier(random_state=42),\n",
    "    \n",
    "#     'xgb1': XGBClassifier(random_state=42)\n",
    "}.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'lr': {\n",
    "        'lr__solver': ['liblinear'],\n",
    "        'lr__penalty': ['l1', 'l2', 'elasticnet'],\n",
    "        'lr__C': np.logspace(1, 5, 20)\n",
    "    },\n",
    "    'knn': {\n",
    "        'knn__n_neighbors': [ 5, 7, 9, 13],\n",
    "#         'weights':['uniform','distance'],\n",
    "#         'algorithm':['ball_tree','kd_tree','brute','auto'],\n",
    "#         'leaf__size':range(1,152),\n",
    "#         'metric':['euclidean','manhatten','minkowski']\n",
    "    },\n",
    "    'ada': {\n",
    "        'ada__n_estimators': [100, 200, 300, 500],\n",
    "        'ada__learning_rate': [1, 1.5, 2]\n",
    "    },\n",
    "    'dtree': {\n",
    "        'dtree__max_depth': [ 3, 5, 10 ,15],\n",
    "        'dtree__max_features': ['auto', 'log2', None, 50, 100],\n",
    "        'dtree__min_samples_split': [5, 10, 20, 30],\n",
    "        'dtree__min_samples_leaf': [ 4, 5, 6, 7]\n",
    "    },\n",
    "    'rf': {\n",
    "        'rf__max_depth': [3, 5, 10, 20, 30],\n",
    "        'rf__max_features': ['auto', 'log2', None, 50],\n",
    "        'rf__min_samples_split': [2, 4, 6, 8],\n",
    "        'rf__min_samples_leaf': [1, 3, 5]\n",
    "    },\n",
    "    'etree': {\n",
    "        'etree__max_depth': [5, 10, 50, 60],\n",
    "        'etree__max_features': ['auto', 'log2', None, 50],\n",
    "        'etree__min_samples_split': [4, 6 ,8, 10],\n",
    "        'etree__min_samples_leaf': [1, 2, 3]\n",
    "    },\n",
    "        \n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting the Optimal Parameters for Each Classifier "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now use RandomizedSearchCV to select the optimal parameters for each classifier that produces the best mean accuracy score based on the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=-1)]: Done 243 out of 250 | elapsed:  5.0min remaining:    8.7s\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:  5.3min finished\n",
      "/Users/joyceooi/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:281: UserWarning: The total space of parameters 4 is smaller than n_iter=50. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  lr\n",
      "Best parameters: {'lr__solver': 'liblinear', 'lr__penalty': 'l2', 'lr__C': 10.0}\n",
      "Best AUC cross validation score: 0.905221099456622\n",
      "Training dataset accuracy: 0.8469871360866622\n",
      "Validation dataset accuracy: 0.8235294117647058\n",
      "Training dataset AUC score: 0.8467598757212607\n",
      "Validation dataset AUC score: 0.8232112870830727\n",
      "Validation dataset sensitivity 0.8406374501992032\n",
      "Validation dataset specificity 0.8057851239669421\n",
      "\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    1.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  knn\n",
      "Best parameters: {'knn__n_neighbors': 13}\n",
      "Best AUC cross validation score: 0.6915634273582614\n",
      "Training dataset accuracy: 0.7373053486797563\n",
      "Validation dataset accuracy: 0.6267748478701826\n",
      "Training dataset AUC score: 0.7373676237009975\n",
      "Validation dataset AUC score: 0.6267985907609231\n",
      "Validation dataset sensitivity 0.6254980079681275\n",
      "Validation dataset specificity 0.628099173553719\n",
      "\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joyceooi/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:281: UserWarning: The total space of parameters 12 is smaller than n_iter=50. Running 12 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   33.9s\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:   49.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  ada\n",
      "Best parameters: {'ada__n_estimators': 100, 'ada__learning_rate': 1.5}\n",
      "Best AUC cross validation score: 0.8797776452787849\n",
      "Training dataset accuracy: 0.8855788761002031\n",
      "Validation dataset accuracy: 0.8174442190669371\n",
      "Training dataset AUC score: 0.8854658435217689\n",
      "Validation dataset AUC score: 0.817457442955451\n",
      "Validation dataset sensitivity 0.8167330677290837\n",
      "Validation dataset specificity 0.8181818181818182\n",
      "\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  dtree\n",
      "Best parameters: {'dtree__min_samples_split': 20, 'dtree__min_samples_leaf': 7, 'dtree__max_features': None, 'dtree__max_depth': 3}\n",
      "Best AUC cross validation score: 0.9004391106995717\n",
      "Training dataset accuracy: 0.8564658090724442\n",
      "Validation dataset accuracy: 0.8154158215010142\n",
      "Training dataset AUC score: 0.8568832007277716\n",
      "Validation dataset AUC score: 0.8157617464028185\n",
      "Validation dataset sensitivity 0.796812749003984\n",
      "Validation dataset specificity 0.8347107438016529\n",
      "\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    9.8s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   46.6s\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  rf\n",
      "Best parameters: {'rf__min_samples_split': 6, 'rf__min_samples_leaf': 3, 'rf__max_features': None, 'rf__max_depth': 3}\n",
      "Best AUC cross validation score: 0.9104623167233401\n",
      "Training dataset accuracy: 0.8530805687203792\n",
      "Validation dataset accuracy: 0.8275862068965517\n",
      "Training dataset AUC score: 0.8533250431930979\n",
      "Validation dataset AUC score: 0.8275657699779395\n",
      "Validation dataset sensitivity 0.8286852589641435\n",
      "Validation dataset specificity 0.8264462809917356\n",
      "\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  62 tasks      | elapsed:    9.6s\n",
      "[Parallel(n_jobs=-1)]: Done 212 tasks      | elapsed:   29.2s\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:   34.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  etree\n",
      "Best parameters: {'etree__min_samples_split': 10, 'etree__min_samples_leaf': 1, 'etree__max_features': None, 'etree__max_depth': 10}\n",
      "Best AUC cross validation score: 0.912401569132879\n",
      "Training dataset accuracy: 0.943805010155721\n",
      "Validation dataset accuracy: 0.8336713995943205\n",
      "Training dataset AUC score: 0.9436628113846368\n",
      "Validation dataset AUC score: 0.8333936979355306\n",
      "Validation dataset sensitivity 0.848605577689243\n",
      "Validation dataset specificity 0.8181818181818182\n",
      "\n",
      "CPU times: user 7.4 s, sys: 384 ms, total: 7.78 s\n",
      "Wall time: 7min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# initialise empty lists to store information later\n",
    "models = []\n",
    "parameters = []\n",
    "train_accuracy = []\n",
    "val_accuracy = []\n",
    "best_score = []\n",
    "train_roc_auc = []\n",
    "val_roc_auc = []\n",
    "sensitivity = []\n",
    "specificity = []\n",
    "\n",
    "for k,v in estimators:\n",
    "    pipe = Pipeline([(k,v)])\n",
    "    param = params[k]\n",
    "    randomsearch = RandomizedSearchCV(\n",
    "        n_iter=50, # we set a max. of 50 iterations\n",
    "        estimator=pipe,\n",
    "        random_state=42,\n",
    "        param_distributions=param,\n",
    "        verbose=1,\n",
    "        cv= 5,\n",
    "        n_jobs=-1,\n",
    "        return_train_score= True,\n",
    "        scoring = 'roc_auc' # we adopt AUC score as our scoring metric as it is provides the best overall assessment\n",
    "    )\n",
    "\n",
    "    randomsearch.fit(X_train_sc, y_train)\n",
    "    \n",
    "    model = randomsearch.best_estimator_\n",
    "    cv_score = randomsearch.cv_results_\n",
    "    best_params = randomsearch.best_params_\n",
    "\n",
    "    # predict y\n",
    "    y_pred_train = model.predict(X_train_sc)\n",
    "    y_pred_valid = model.predict(X_valid_sc)\n",
    "    \n",
    "    # print results\n",
    "    print (\"Model: \", k)\n",
    "    print (\"Best parameters:\", best_params)\n",
    "    print (\"Best AUC cross validation score:\", randomsearch.best_score_)\n",
    "    print (\"Training dataset accuracy:\", accuracy_score(y_train,y_pred_train))\n",
    "    print (\"Validation dataset accuracy:\", accuracy_score(y_valid,y_pred_valid))\n",
    "    print (\"Training dataset AUC score:\", roc_auc_score(y_train,y_pred_train))\n",
    "    print (\"Validation dataset AUC score:\", roc_auc_score(y_valid,y_pred_valid))\n",
    "    # obtain true positive and false negatives to calculate sensitivity\n",
    "    tn, fp, fn, tp = confusion_matrix(y_valid, y_pred_valid).ravel() \n",
    "    print (\"Validation dataset sensitivity\", tp/(tp+fn))\n",
    "    print (\"Validation dataset specificity\", tn/(tn+fp))\n",
    "    print (\"\")\n",
    "    \n",
    "    # append info to list\n",
    "    models.append(k)\n",
    "    best_score.append(randomsearch.best_score_)\n",
    "    parameters.append(best_params)\n",
    "    train_accuracy.append(accuracy_score(y_train,y_pred_train))\n",
    "    val_accuracy.append(accuracy_score(y_valid,y_pred_valid))\n",
    "    train_roc_auc.append(roc_auc_score(y_train,y_pred_train))\n",
    "    val_roc_auc.append(roc_auc_score(y_valid,y_pred_valid))\n",
    "    sensitivity.append(tp/(tp+fn))\n",
    "    specificity.append(tn/(tn+fp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection of the Best Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joyceooi/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:14: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>parameters</th>\n",
       "      <th>Best AUC cross validation score</th>\n",
       "      <th>Training dataset accuracy</th>\n",
       "      <th>Validation dataset accuracy</th>\n",
       "      <th>Training dataset AUC score</th>\n",
       "      <th>Validation dataset AUC score</th>\n",
       "      <th>Validation dataset sensitivity</th>\n",
       "      <th>Validation dataset specificity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>etree</td>\n",
       "      <td>{'etree__min_samples_split': 10, 'etree__min_samples_leaf': 1, 'etree__max_features': None, 'etree__max_depth': 10}</td>\n",
       "      <td>0.912402</td>\n",
       "      <td>0.943805</td>\n",
       "      <td>0.833671</td>\n",
       "      <td>0.943663</td>\n",
       "      <td>0.833394</td>\n",
       "      <td>0.848606</td>\n",
       "      <td>0.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rf</td>\n",
       "      <td>{'rf__min_samples_split': 6, 'rf__min_samples_leaf': 3, 'rf__max_features': None, 'rf__max_depth': 3}</td>\n",
       "      <td>0.910462</td>\n",
       "      <td>0.853081</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.853325</td>\n",
       "      <td>0.827566</td>\n",
       "      <td>0.828685</td>\n",
       "      <td>0.826446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lr</td>\n",
       "      <td>{'lr__solver': 'liblinear', 'lr__penalty': 'l2', 'lr__C': 10.0}</td>\n",
       "      <td>0.905221</td>\n",
       "      <td>0.846987</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.846760</td>\n",
       "      <td>0.823211</td>\n",
       "      <td>0.840637</td>\n",
       "      <td>0.805785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ada</td>\n",
       "      <td>{'ada__n_estimators': 100, 'ada__learning_rate': 1.5}</td>\n",
       "      <td>0.879778</td>\n",
       "      <td>0.885579</td>\n",
       "      <td>0.817444</td>\n",
       "      <td>0.885466</td>\n",
       "      <td>0.817457</td>\n",
       "      <td>0.816733</td>\n",
       "      <td>0.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dtree</td>\n",
       "      <td>{'dtree__min_samples_split': 20, 'dtree__min_samples_leaf': 7, 'dtree__max_features': None, 'dtree__max_depth': 3}</td>\n",
       "      <td>0.900439</td>\n",
       "      <td>0.856466</td>\n",
       "      <td>0.815416</td>\n",
       "      <td>0.856883</td>\n",
       "      <td>0.815762</td>\n",
       "      <td>0.796813</td>\n",
       "      <td>0.834711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>knn</td>\n",
       "      <td>{'knn__n_neighbors': 13}</td>\n",
       "      <td>0.691563</td>\n",
       "      <td>0.737305</td>\n",
       "      <td>0.626775</td>\n",
       "      <td>0.737368</td>\n",
       "      <td>0.626799</td>\n",
       "      <td>0.625498</td>\n",
       "      <td>0.628099</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model  \\\n",
       "0  etree   \n",
       "1  rf      \n",
       "2  lr      \n",
       "3  ada     \n",
       "4  dtree   \n",
       "5  knn     \n",
       "\n",
       "                                                                                                            parameters  \\\n",
       "0  {'etree__min_samples_split': 10, 'etree__min_samples_leaf': 1, 'etree__max_features': None, 'etree__max_depth': 10}   \n",
       "1  {'rf__min_samples_split': 6, 'rf__min_samples_leaf': 3, 'rf__max_features': None, 'rf__max_depth': 3}                 \n",
       "2  {'lr__solver': 'liblinear', 'lr__penalty': 'l2', 'lr__C': 10.0}                                                       \n",
       "3  {'ada__n_estimators': 100, 'ada__learning_rate': 1.5}                                                                 \n",
       "4  {'dtree__min_samples_split': 20, 'dtree__min_samples_leaf': 7, 'dtree__max_features': None, 'dtree__max_depth': 3}    \n",
       "5  {'knn__n_neighbors': 13}                                                                                              \n",
       "\n",
       "   Best AUC cross validation score  Training dataset accuracy  \\\n",
       "0  0.912402                         0.943805                    \n",
       "1  0.910462                         0.853081                    \n",
       "2  0.905221                         0.846987                    \n",
       "3  0.879778                         0.885579                    \n",
       "4  0.900439                         0.856466                    \n",
       "5  0.691563                         0.737305                    \n",
       "\n",
       "   Validation dataset accuracy  Training dataset AUC score  \\\n",
       "0  0.833671                     0.943663                     \n",
       "1  0.827586                     0.853325                     \n",
       "2  0.823529                     0.846760                     \n",
       "3  0.817444                     0.885466                     \n",
       "4  0.815416                     0.856883                     \n",
       "5  0.626775                     0.737368                     \n",
       "\n",
       "   Validation dataset AUC score  Validation dataset sensitivity  \\\n",
       "0  0.833394                      0.848606                         \n",
       "1  0.827566                      0.828685                         \n",
       "2  0.823211                      0.840637                         \n",
       "3  0.817457                      0.816733                         \n",
       "4  0.815762                      0.796813                         \n",
       "5  0.626799                      0.625498                         \n",
       "\n",
       "   Validation dataset specificity  \n",
       "0  0.818182                        \n",
       "1  0.826446                        \n",
       "2  0.805785                        \n",
       "3  0.818182                        \n",
       "4  0.834711                        \n",
       "5  0.628099                        "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Produce a summary table of the tuned classifiers\n",
    "summary = pd.DataFrame({\n",
    "    'model': models,\n",
    "    'parameters': parameters,\n",
    "    'Best AUC cross validation score': best_score,\n",
    "    'Training dataset accuracy': train_accuracy,\n",
    "    'Validation dataset accuracy': val_accuracy,\n",
    "    'Training dataset AUC score': train_roc_auc,\n",
    "    'Validation dataset AUC score': val_roc_auc,\n",
    "    'Validation dataset sensitivity': sensitivity,\n",
    "    'Validation dataset specificity': specificity\n",
    "    })\n",
    "\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "summary.sort_values('Validation dataset AUC score', ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table above shows the performance of the various models in terms of their optimal parameters, and the different metrics used to evaluate the models, including and not limited to, accuracy, AUC and F1 scores.\n",
    "\n",
    "We note that most models performed reasonably in terms of AUC cross validation scores with **most models scoring above 81%**. We will choose to further explore all model classifiers on unseen data. As our test dataset comprises of the oulast 466 trading days between 30/04/2018 till 16/04/2020, with high volatility of Tesla share price ranging from USD290 to about USD882 and down to USD681, we expect the results from unseen data to perform less well.\n",
    "\n",
    "So far, our best performing model on validation data is Exra Trees. Besides having the highest AUC validation score (0.8333) it also has the highest validation accuracy (0.8336) and the highest sensitivity (0.848), which is an important metric that we wish to focus on.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further exploration of the Best Classifier on Unseen Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn=KNeighborsClassifier(n_neighbors=9, weights='distance',metric='euclidean' , algorithm='kd_tree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='kd_tree', leaf_size=30, metric='euclidean',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=9, p=2,\n",
       "                     weights='distance')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(X_train_sc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_pred = pd.DataFrame(knn.predict(X_testuntrain_sc), columns=['tsla_intra_target'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenate the predictions  with the X_testuntrain dataframe\n",
    "test_pred= pd.concat([X_testuntrain,knn_pred], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_testuntrain, knn_pred).ravel() \n",
    "precision=tp/(tp+fp)\n",
    "recall=tp/(tp+fn)\n",
    "accuracy=(tp+tn)/(tp+tn+fp+fn)\n",
    "sensitivity=(tp/(tp+fn))\n",
    "specificity=(tn/(tn+fp))\n",
    "F1=(precision*recall)/precision+recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.6115879828326181\n",
      "Precision:0.5726495726495726\n",
      "Sensitivity:0.6232558139534884\n",
      "Specificity:0.601593625498008\n",
      "Recall:0.6232558139534884\n",
      "F1 Score:0.5968819599109132\n"
     ]
    }
   ],
   "source": [
    "print (\"Accuracy:{}\".format(accuracy)),\n",
    "print (\"Precision:{}\".format(precision)),\n",
    "print (\"Sensitivity:{}\".format(sensitivity)),\n",
    "print (\"Specificity:{}\".format(specificity)),\n",
    "print (\"Recall:{}\".format(recall)),\n",
    "print (\"F1 Score:{}\".format(2*((precision*recall)/(precision+recall))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf=RandomForestClassifier(random_state=42, min_samples_split=2, min_samples_leaf=3, max_features= 'log2',\n",
    "                          max_depth=5 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=5, max_features='log2',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=3, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(X_train_sc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pred = pd.DataFrame(rf.predict(X_testuntrain_sc), columns=['tsla_intra_target'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenate the predictions  with the X_testuntrain dataframe\n",
    "test_pred= pd.concat([X_testuntrain,rf_pred], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_testuntrain, rf_pred).ravel() \n",
    "precision=tp/(tp+fp)\n",
    "recall=tp/(tp+fn)\n",
    "accuracy=(tp+tn)/(tp+tn+fp+fn)\n",
    "ensitivity=(tp/(tp+fn))\n",
    "specificity=(tn/(tn+fp))\n",
    "F1=(precision*recall)/precision+recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.7896995708154506\n",
      "Precision:0.7554585152838428\n",
      "Sensitivity:0.6232558139534884\n",
      "Specificity:0.7768924302788844\n",
      "Recall:0.8046511627906977\n",
      "F1 Score:0.7792792792792792\n"
     ]
    }
   ],
   "source": [
    "print (\"Accuracy:{}\".format(accuracy)),\n",
    "print (\"Precision:{}\".format(precision)),\n",
    "print (\"Sensitivity:{}\".format(sensitivity)),\n",
    "print (\"Specificity:{}\".format(specificity)),\n",
    "print (\"Recall:{}\".format(recall)),\n",
    "print (\"F1 Score:{}\".format(2*((precision*recall)/(precision+recall))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada=AdaBoostClassifier(random_state=42, n_estimators=600, learning_rate=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.5,\n",
       "                   n_estimators=600, random_state=42)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada.fit(X_train_sc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_pred = pd.DataFrame(ada.predict(X_testuntrain_sc), columns=['tsla_intra_target'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenate the predictions  with the X_testuntrain dataframe\n",
    "test_pred= pd.concat([X_testuntrain,ada_pred], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_testuntrain, ada_pred).ravel() \n",
    "precision=tp/(tp+fp)\n",
    "recall=tp/(tp+fn)\n",
    "accuracy=(tp+tn)/(tp+tn+fp+fn)\n",
    "ensitivity=(tp/(tp+fn))\n",
    "specificity=(tn/(tn+fp))\n",
    "F1=(precision*recall)/precision+recall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.7639484978540773\n",
      "Precision:0.7419354838709677\n",
      "Sensitivity:0.6232558139534884\n",
      "Specificity:0.7768924302788844\n",
      "Recall:0.7488372093023256\n",
      "F1 Score:0.7453703703703703\n"
     ]
    }
   ],
   "source": [
    "print (\"Accuracy:{}\".format(accuracy)),\n",
    "print (\"Precision:{}\".format(precision)),\n",
    "print (\"Sensitivity:{}\".format(sensitivity)),\n",
    "print (\"Specificity:{}\".format(specificity)),\n",
    "print (\"Recall:{}\".format(recall)),\n",
    "print (\"F1 Score:{}\".format(2*((precision*recall)/(precision+recall))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DTREE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree= DecisionTreeClassifier(random_state=42, min_samples_split=10, min_samples_leaf=6,max_features='auto',max_depth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=3, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=6, min_samples_split=10,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=42, splitter='best')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtree.fit(X_train_sc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree_pred = pd.DataFrame(dtree.predict(X_testuntrain_sc), columns=['tsla_intra_target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenate the predictions  with the X_testuntrain dataframe\n",
    "test_pred= pd.concat([X_testuntrain,dtree_pred], axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_testuntrain, dtree_pred).ravel() \n",
    "precision=tp/(tp+fp)\n",
    "recall=tp/(tp+fn)\n",
    "accuracy=(tp+tn)/(tp+tn+fp+fn)\n",
    "ensitivity=(tp/(tp+fn))\n",
    "specificity=(tn/(tn+fp))\n",
    "F1=(precision*recall)/precision+recall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.7811158798283262\n",
      "Precision:0.7467248908296943\n",
      "Sensitivity:0.6232558139534884\n",
      "Specificity:0.7689243027888446\n",
      "Recall:0.7953488372093023\n",
      "F1 Score:0.7702702702702703\n"
     ]
    }
   ],
   "source": [
    "print (\"Accuracy:{}\".format(accuracy)),\n",
    "print (\"Precision:{}\".format(precision)),\n",
    "print (\"Sensitivity:{}\".format(sensitivity)),\n",
    "print (\"Specificity:{}\".format(specificity)),\n",
    "print (\"Recall:{}\".format(recall)),\n",
    "print (\"F1 Score:{}\".format(2*((precision*recall)/(precision+recall))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETREE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "etree= ExtraTreesClassifier(random_state=42, min_samples_split=8,min_samples_leaf=2,max_features=None ,max_depth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
       "                     criterion='gini', max_depth=5, max_features=None,\n",
       "                     max_leaf_nodes=None, max_samples=None,\n",
       "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                     min_samples_leaf=2, min_samples_split=8,\n",
       "                     min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                     n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
       "                     warm_start=False)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "etree.fit(X_train_sc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "etree_pred = pd.DataFrame(etree.predict(X_testuntrain_sc), columns=['tsla_intra_target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenate the predictions  with the X_testuntrain dataframe\n",
    "test_pred= pd.concat([X_testuntrain,etree_pred], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_testuntrain, etree_pred).ravel() \n",
    "precision=tp/(tp+fp)\n",
    "recall=tp/(tp+fn)\n",
    "accuracy=(tp+tn)/(tp+tn+fp+fn)\n",
    "ensitivity=(tp/(tp+fn))\n",
    "specificity=(tn/(tn+fp))\n",
    "F1=(precision*recall)/precision+recall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.7811158798283262\n",
      "Precision:0.7424892703862661\n",
      "Sensitivity:0.6232558139534884\n",
      "Specificity:0.7609561752988048\n",
      "Recall:0.8046511627906977\n",
      "F1 Score:0.7723214285714286\n"
     ]
    }
   ],
   "source": [
    "print (\"Accuracy:{}\".format(accuracy)),\n",
    "print (\"Precision:{}\".format(precision)),\n",
    "print (\"Sensitivity:{}\".format(sensitivity)),\n",
    "print (\"Specificity:{}\".format(specificity)),\n",
    "print (\"Recall:{}\".format(recall)),\n",
    "print (\"F1 Score:{}\".format(2*((precision*recall)/(precision+recall))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr =LogisticRegression(penalty='l1', solver='liblinear', C=10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l1',\n",
       "                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_train_sc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pred = pd.DataFrame(lr.predict(X_testuntrain_sc), columns=['tsla_intra_target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenate the predictions  with the X_testuntrain dataframe\n",
    "test_pred= pd.concat([X_testuntrain,lr_pred], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_testuntrain, lr_pred).ravel() \n",
    "precision=tp/(tp+fp)\n",
    "recall=tp/(tp+fn)\n",
    "accuracy=(tp+tn)/(tp+tn+fp+fn)\n",
    "sensitivity=(tp/(tp+fn))\n",
    "specificity=(tn/(tn+fp))\n",
    "F1=(precision*recall)/precision+recall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.7682403433476395\n",
      "Precision:0.7131474103585658\n",
      "Sensitivity:0.8325581395348837\n",
      "Specificity:0.7131474103585658\n",
      "Recall:0.8325581395348837\n",
      "F1 Score:0.7682403433476396\n"
     ]
    }
   ],
   "source": [
    "print (\"Accuracy:{}\".format(accuracy)),\n",
    "print (\"Precision:{}\".format(precision)),\n",
    "print (\"Sensitivity:{}\".format(sensitivity)),\n",
    "print (\"Specificity:{}\".format(specificity)),\n",
    "print (\"Recall:{}\".format(recall)),\n",
    "print (\"F1 Score:{}\".format(2*((precision*recall)/(precision+recall))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation of Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_proba=[i[1] for i in rf.predict_proba(X_testuntrain_sc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df=pd.DataFrame ({'true_values':y_testuntrain,\n",
    "                      'pred_probs': pred_proba})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true_values</th>\n",
       "      <th>pred_probs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.376862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.321193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.359432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.325345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.446651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.651262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.346046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.383969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.365781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.607834</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    true_values  pred_probs\n",
       "0   0.0          0.376862  \n",
       "1   1.0          0.321193  \n",
       "2   1.0          0.359432  \n",
       "3   0.0          0.325345  \n",
       "4   0.0          0.446651  \n",
       "..  ...               ...  \n",
       "95  1.0          0.651262  \n",
       "96  1.0          0.346046  \n",
       "97  0.0          0.383969  \n",
       "98  1.0          0.365781  \n",
       "99  0.0          0.607834  \n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUC Scores on Unseen Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score for KNN: 0.6124247197257482\n",
      "AUC Score for RF: 0.790771796534791\n",
      "AUC Score for ADA: 0.762864819790605\n",
      "AUC Score for DTREE: 0.7821365699990734\n",
      "AUC Score for ETREE: 0.7828036690447512\n",
      "AUC Score for LR: 0.7728527749467248\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('AUC Score for KNN: {}'.format(roc_auc_score(y_testuntrain,knn_pred)))\n",
    "print('AUC Score for RF: {}'.format(roc_auc_score(y_testuntrain,rf_pred)))\n",
    "print('AUC Score for ADA: {}'.format(roc_auc_score(y_testuntrain,ada_pred)))\n",
    "print('AUC Score for DTREE: {}'.format(roc_auc_score(y_testuntrain,dtree_pred)))\n",
    "print('AUC Score for ETREE: {}'.format(roc_auc_score(y_testuntrain,etree_pred)))\n",
    "print('AUC Score for LR: {}'.format(roc_auc_score(y_testuntrain,lr_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create figure.\n",
    "plt.figure(figsize = (10,7))\n",
    "\n",
    "# Create threshold values.\n",
    "thresholds = np.linspace(0, 1, 200)\n",
    "\n",
    "# Define function to calculate sensitivity. (True positive rate.)\n",
    "def TPR(df, true_col, pred_prob_col, threshold):\n",
    "    true_positive = df[(df[true_col] == 1) & (df[pred_prob_col] >= threshold)].shape[0]\n",
    "    false_negative = df[(df[true_col] == 1) & (df[pred_prob_col] < threshold)].shape[0]\n",
    "    return true_positive / (true_positive + false_negative)\n",
    "    \n",
    "\n",
    "# Define function to calculate 1 - specificity. (False positive rate.)\n",
    "def FPR(df, true_col, pred_prob_col, threshold):\n",
    "    true_negative = df[(df[true_col] == 0) & (df[pred_prob_col] <= threshold)].shape[0]\n",
    "    false_positive = df[(df[true_col] == 0) & (df[pred_prob_col] > threshold)].shape[0]\n",
    "    return 1 - (true_negative / (true_negative + false_positive))\n",
    "    \n",
    "# Calculate sensitivity & 1-specificity for each threshold between 0 and 1.\n",
    "tpr_values = [TPR(pred_df, 'true_values', 'pred_probs', prob) for prob in thresholds]\n",
    "fpr_values = [FPR(pred_df, 'true_values', 'pred_probs', prob) for prob in thresholds]\n",
    "\n",
    "# Plot ROC curve.\n",
    "plt.plot(fpr_values, # False Positive Rate on X-axis\n",
    "         tpr_values, # True Positive Rate on Y-axis\n",
    "         label='ROC Curve')\n",
    "\n",
    "# Plot baseline. (Perfect overlap between the two populations.)\n",
    "plt.plot(np.linspace(0, 1, 200),\n",
    "         np.linspace(0, 1, 200),\n",
    "         label='baseline',\n",
    "         linestyle='--')\n",
    "\n",
    "# Label axes.\n",
    "plt.title('Receiver Operating Characteristic Curve', fontsize=22)\n",
    "plt.ylabel('Sensitivity', fontsize=18)\n",
    "plt.xlabel('1 - Specificity', fontsize=18)\n",
    "\n",
    "# Create legend.\n",
    "plt.legend(fontsize=16);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpreting ROC AUC**\n",
    "\n",
    "ROC is a probability curve and AUC represents the degree of separability i.e. the capability of the model in distinguishing between a positive or negative return. The higher the AUC, the better the model is at predicting 0s as 0s and 1s as 1s. If AUC is 1, the positive (Tesla Stock Price = 1) and negative (Tesla Stock Price = 0) are perfectly separated. \n",
    "\n",
    "Here, we have **an AUC of 0.7908 for Random Forest** which is our best model. This means that 79% of the predictions are accurately classified.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Conclusions and Recommendations\n",
    "\n",
    "### A. Our Classifier\n",
    "\n",
    "We have tried several classifiers to predict whether Tesla share price will increase or decrease. **Random Forest** does the best job of classification compared to the other models and acheved the following scores:\n",
    "\n",
    "- Accuracy:0.7896995708154506\n",
    "- Precision:0.7554585152838428\n",
    "- Sensitivity:0.6232558139534884\n",
    "- Specificity:0.7768924302788844\n",
    "- Recall:0.8046511627906977\n",
    "- F1 Score:0.7792792792792792 \n",
    "\n",
    "F1 Score is the weighted average of Precision and Recall that takes both false positives and false negatives into account. We view Specificity which refers to when the predicted class is positive(1) but actual class is zero (0), as important, during this Covid 19 period. As crisis periods usually present opportunities to buy assets at lower prices, wrong investment could result in high opportunity cost in terms of alternative use of funds during this critical period.\n",
    "\n",
    "**Limitations**\n",
    "\n",
    "1. Financial market forecasting is one of the most difficult practical applications and especially given market volatility. An even better score may have been attained by employing a more sophisticated model and deeper learning approach. One consideration could have been the use of LSTM, RNN and ARIMA which could have been combined in a Feedforward Neural Network to give a more accurate prediction. An approach of combining different methods through Ensemble learning could also have been adopted.\n",
    "\n",
    "**Advantages**\n",
    "1. Combines both endogenous and exogenous approach which is more holistic.\n",
    "2. Scores were reasonable although improvements could certainly be made.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
